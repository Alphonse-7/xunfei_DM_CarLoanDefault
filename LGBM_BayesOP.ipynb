{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# import scipy.sparse    # 稀疏矩阵的处理\n",
    "# import pickle\n",
    "\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Jupyter_code\\\\Competition\\\\xunfei_datawhale_DM\\\\1_车辆贷款违约预测挑战赛'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "sample_submit = pd.read_csv('input/sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['main_active_loan_ratio'] = train['main_account_active_loan_no']/train['main_account_loan_no']\n",
    "# # train['main_active_loan_ratio'] = train['main_active_loan_ratio'].fillna(0)\n",
    "\n",
    "# train['active_overdue_loan_ratio'] = train['main_account_active_loan_no']/train['main_account_loan_no']\n",
    "# # train['active_overdue_loan_ratio'] = train['main_active_loan_ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 53 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   customer_id                    150000 non-null  int64  \n",
      " 1   main_account_loan_no           150000 non-null  int64  \n",
      " 2   main_account_active_loan_no    150000 non-null  int64  \n",
      " 3   main_account_overdue_no        150000 non-null  int64  \n",
      " 4   main_account_outstanding_loan  150000 non-null  int64  \n",
      " 5   main_account_sanction_loan     150000 non-null  int64  \n",
      " 6   main_account_disbursed_loan    150000 non-null  int64  \n",
      " 7   sub_account_loan_no            150000 non-null  int64  \n",
      " 8   sub_account_active_loan_no     150000 non-null  int64  \n",
      " 9   sub_account_overdue_no         150000 non-null  int64  \n",
      " 10  sub_account_outstanding_loan   150000 non-null  int64  \n",
      " 11  sub_account_sanction_loan      150000 non-null  int64  \n",
      " 12  sub_account_disbursed_loan     150000 non-null  int64  \n",
      " 13  disbursed_amount               150000 non-null  int64  \n",
      " 14  asset_cost                     150000 non-null  int64  \n",
      " 15  branch_id                      150000 non-null  int64  \n",
      " 16  supplier_id                    150000 non-null  int64  \n",
      " 17  manufacturer_id                150000 non-null  int64  \n",
      " 18  area_id                        150000 non-null  int64  \n",
      " 19  employee_code_id               150000 non-null  int64  \n",
      " 20  mobileno_flag                  150000 non-null  int64  \n",
      " 21  idcard_flag                    150000 non-null  int64  \n",
      " 22  Driving_flag                   150000 non-null  int64  \n",
      " 23  passport_flag                  150000 non-null  int64  \n",
      " 24  credit_score                   150000 non-null  int64  \n",
      " 25  main_account_monthly_payment   150000 non-null  int64  \n",
      " 26  sub_account_monthly_payment    150000 non-null  int64  \n",
      " 27  last_six_month_new_loan_no     150000 non-null  int64  \n",
      " 28  last_six_month_defaulted_no    150000 non-null  int64  \n",
      " 29  average_age                    150000 non-null  int64  \n",
      " 30  credit_history                 150000 non-null  int64  \n",
      " 31  enquirie_no                    150000 non-null  int64  \n",
      " 32  loan_to_asset_ratio            150000 non-null  float64\n",
      " 33  total_account_loan_no          150000 non-null  int64  \n",
      " 34  sub_account_inactive_loan_no   150000 non-null  int64  \n",
      " 35  total_inactive_loan_no         150000 non-null  int64  \n",
      " 36  main_account_inactive_loan_no  150000 non-null  int64  \n",
      " 37  total_overdue_no               150000 non-null  int64  \n",
      " 38  total_outstanding_loan         150000 non-null  int64  \n",
      " 39  total_sanction_loan            150000 non-null  int64  \n",
      " 40  total_disbursed_loan           150000 non-null  int64  \n",
      " 41  total_monthly_payment          150000 non-null  int64  \n",
      " 42  outstanding_disburse_ratio     150000 non-null  float64\n",
      " 43  main_account_tenure            150000 non-null  int64  \n",
      " 44  sub_account_tenure             150000 non-null  int64  \n",
      " 45  disburse_to_sactioned_ratio    150000 non-null  float64\n",
      " 46  active_to_inactive_act_ratio   150000 non-null  float64\n",
      " 47  year_of_birth                  150000 non-null  int64  \n",
      " 48  disbursed_date                 150000 non-null  int64  \n",
      " 49  Credit_level                   150000 non-null  int64  \n",
      " 50  employment_type                150000 non-null  int64  \n",
      " 51  age                            150000 non-null  int64  \n",
      " 52  loan_default                   150000 non-null  int64  \n",
      "dtypes: float64(4), int64(49)\n",
      "memory usage: 60.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>main_account_loan_no</th>\n",
       "      <th>main_account_active_loan_no</th>\n",
       "      <th>main_account_overdue_no</th>\n",
       "      <th>main_account_outstanding_loan</th>\n",
       "      <th>main_account_sanction_loan</th>\n",
       "      <th>main_account_disbursed_loan</th>\n",
       "      <th>sub_account_loan_no</th>\n",
       "      <th>sub_account_active_loan_no</th>\n",
       "      <th>sub_account_overdue_no</th>\n",
       "      <th>...</th>\n",
       "      <th>main_account_tenure</th>\n",
       "      <th>sub_account_tenure</th>\n",
       "      <th>disburse_to_sactioned_ratio</th>\n",
       "      <th>active_to_inactive_act_ratio</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>disbursed_date</th>\n",
       "      <th>Credit_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>age</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105691</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>384989</td>\n",
       "      <td>666207</td>\n",
       "      <td>666207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1968</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24938</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>268670</td>\n",
       "      <td>387994</td>\n",
       "      <td>387994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1992</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104389</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3519013</td>\n",
       "      <td>3613854</td>\n",
       "      <td>3576048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3576048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1991</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54688</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1867106</td>\n",
       "      <td>2484678</td>\n",
       "      <td>2486856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1964</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1995</td>\n",
       "      <td>2019</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  main_account_loan_no  main_account_active_loan_no  \\\n",
       "0       105691                     4                            3   \n",
       "1        24938                     7                            2   \n",
       "2       104389                     5                            4   \n",
       "3        54688                    43                           13   \n",
       "4        63894                     0                            0   \n",
       "\n",
       "   main_account_overdue_no  main_account_outstanding_loan  \\\n",
       "0                        0                         384989   \n",
       "1                        0                         268670   \n",
       "2                        1                        3519013   \n",
       "3                        6                        1867106   \n",
       "4                        0                              0   \n",
       "\n",
       "   main_account_sanction_loan  main_account_disbursed_loan  \\\n",
       "0                      666207                       666207   \n",
       "1                      387994                       387994   \n",
       "2                     3613854                      3576048   \n",
       "3                     2484678                      2486856   \n",
       "4                           0                            0   \n",
       "\n",
       "   sub_account_loan_no  sub_account_active_loan_no  sub_account_overdue_no  \\\n",
       "0                    0                           0                       0   \n",
       "1                    0                           0                       0   \n",
       "2                    0                           0                       0   \n",
       "3                    0                           0                       0   \n",
       "4                    0                           0                       0   \n",
       "\n",
       "   ...  main_account_tenure  sub_account_tenure  disburse_to_sactioned_ratio  \\\n",
       "0  ...                   81                   0                         1.00   \n",
       "1  ...                  161                   0                         1.00   \n",
       "2  ...              3576048                   0                         0.99   \n",
       "3  ...                    0                   0                         1.00   \n",
       "4  ...                    0                   0                         1.00   \n",
       "\n",
       "   active_to_inactive_act_ratio  year_of_birth  disbursed_date  Credit_level  \\\n",
       "0                          2.50           1968            2019             1   \n",
       "1                          1.33           1992            2019             9   \n",
       "2                          3.00           1991            2019            13   \n",
       "3                          1.42           1964            2019             3   \n",
       "4                          1.00           1995            2019            -1   \n",
       "\n",
       "   employment_type  age  loan_default  \n",
       "0                0   51             0  \n",
       "1                0   27             0  \n",
       "2                1   28             0  \n",
       "3                1   55             0  \n",
       "4                0   24             0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cols = [f for f in train.columns if f not in ['customer_id','loan_default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train[all_cols]\n",
    "# x_test = test[all_cols]\n",
    "# y_train = train['loan_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['customer_id','mobileno_flag', 'idcard_flag', 'disbursed_date','loan_default'],axis=1)\n",
    "y = train['loan_default']\n",
    "X_test = test.drop(['customer_id','mobileno_flag', 'idcard_flag', 'disbursed_date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "#     folds = 5\n",
    "#     seed = 2020\n",
    "#     kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "#     train = np.zeros(train_x.shape[0])\n",
    "#     test = np.zeros(test_x.shape[0])\n",
    "\n",
    "#     cv_scores = []\n",
    "\n",
    "#     for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "#         print('************************************ {} ************************************'.format(str(i+1)))\n",
    "#         trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "#         if clf_name == \"lgb\":\n",
    "#             train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "#             valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "#             params = {\n",
    "#                 'boosting_type': 'gbdt',\n",
    "#                 'objective': 'binary',\n",
    "#                 'metric': 'auc',\n",
    "#                 'min_child_weight': 5,\n",
    "#                 'num_leaves': 2 ** 5,\n",
    "#                 'lambda_l2': 10,\n",
    "#                 'feature_fraction': 0.8,\n",
    "#                 'bagging_fraction': 0.8,\n",
    "#                 'bagging_freq': 4,\n",
    "#                 'learning_rate': 0.1,\n",
    "#                 'seed': 2020,\n",
    "#                 'nthread': 28,\n",
    "#                 'n_jobs':24,\n",
    "#                 'silent': True,\n",
    "#                 'verbose': -1,\n",
    "#             }\n",
    "\n",
    "#             model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "#             val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "#             test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "#             # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "#         if clf_name == \"xgb\":\n",
    "#             train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "#             valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            \n",
    "#             params = {'booster': 'gbtree',\n",
    "#                       'objective': 'binary:logistic',\n",
    "#                       'eval_metric': 'auc',\n",
    "#                       'gamma': 1,\n",
    "#                       'min_child_weight': 1.5,\n",
    "#                       'max_depth': 5,\n",
    "#                       'lambda': 10,\n",
    "#                       'subsample': 0.7,\n",
    "#                       'colsample_bytree': 0.7,\n",
    "#                       'colsample_bylevel': 0.7,\n",
    "#                       'eta': 0.04,\n",
    "#                       'tree_method': 'exact',\n",
    "#                       'seed': 2020,\n",
    "#                       'nthread': 36,\n",
    "#                       \"silent\": True,\n",
    "#                       }\n",
    "            \n",
    "#             watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "#             model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "#             val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "#             test_pred = model.predict(xgb.DMatrix(test_x) , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "#         if clf_name == \"cat\":\n",
    "#             params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "#                       'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "#             model = clf(iterations=20000, **params)\n",
    "#             model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "#                       cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "#             val_pred  = model.predict(val_x)\n",
    "#             test_pred = model.predict(test_x)\n",
    "            \n",
    "#         train[valid_index] = val_pred\n",
    "#         test = test_pred / kf.n_splits\n",
    "#         cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "#         print(cv_scores)\n",
    "        \n",
    "#     print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "#     print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "#     print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "#     return train, test\n",
    "\n",
    "# def xgb_model(x_train, y_train, x_test):\n",
    "#     xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "#     return xgb_train, xgb_test\n",
    "\n",
    "\n",
    "# lgb_train, lgb_test = xgb_model(X, y, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_label(x,threshold):\n",
    "    labels = x.copy()\n",
    "    labels[labels<threshold]=0\n",
    "    labels[labels>=threshold]=1\n",
    "    return labels\n",
    "\n",
    "# (440000 + 165000*(1 - np.exp((-0.3) * x / 6)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def feval_RMSPE(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "def f1_score_custom(y_true, y_pred):\n",
    "    y_pred = y_pred.round()\n",
    "    return 'f1', f1_score(y_true, y_pred,average='macro'), True\n",
    "\n",
    "def floss(prediction, target, beta=1, log_like=False):\n",
    "    EPS = 1e-10\n",
    "    # print(prediction)\n",
    "    N = prediction.size\n",
    "    TP = (prediction * target).sum()\n",
    "#     TP = np.logical_and(prediction,target).sum()\n",
    "    H = beta * target.sum() + prediction.sum()\n",
    "    fmeasure = (1 + beta) * TP / (H + EPS)\n",
    "    if log_like:\n",
    "        floss_ = -torch.log(fmeasure)\n",
    "    else:\n",
    "        floss_  = (1 - fmeasure)\n",
    "    return floss_\n",
    "\n",
    "def floss_macro(prediction, target, beta=1, log_like=False):\n",
    "    EPS = 1e-10\n",
    "    prediction_inv = np.logical_not(prediction)\n",
    "    target_inv = np.logical_not(target)\n",
    "    \n",
    "    TP_0 = (prediction_inv * target_inv).sum()\n",
    "    H_0 = beta * target_inv.sum() + prediction_inv.sum()\n",
    "    fmeasure_0 = (1 + beta) * TP_0 / (H_0 + EPS)\n",
    "    \n",
    "    TP_1 = (prediction * target).sum()\n",
    "    H_1 = beta * target.sum() + prediction.sum()\n",
    "    fmeasure_1 = (1 + beta) * TP_1 / (H_1 + EPS)\n",
    "    \n",
    "    fmeasure = (fmeasure_0+fmeasure_1)/2\n",
    "    if log_like:\n",
    "        floss_ = -torch.log(fmeasure)\n",
    "    else:\n",
    "        floss_  = - fmeasure\n",
    "    return floss_\n",
    "\n",
    "def floss_macro_2(prediction, target):\n",
    "    return -f1_score(target,prediction,average='macro')\n",
    "    \n",
    "\n",
    "\n",
    "def feval_floss(preds, lgbm_train,threshold):\n",
    "    labels = lgbm_train.get_label()\n",
    "    preds = prob_to_label(preds,threshold=threshold)\n",
    "    return 'floss', round(floss(target = labels, prediction = preds),5), False\n",
    "\n",
    "def feval_floss_macro(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "#     print('labels_sum: ',labels.sum())\n",
    "#     print(preds)\n",
    "    preds = prob_to_label(preds,threshold=threshold)\n",
    "#     print('pred_sum: ',preds.sum())\n",
    "#     print(round(floss_macro(target = labels, prediction = preds),5))\n",
    "    return 'floss_macro', round(floss_macro(target = labels, prediction = preds),5), False\n",
    "\n",
    "def feval_floss_macro_xgb(preds, train_matrix):\n",
    "    labels = train_matrix.get_label()\n",
    "#     print('labels_sum: ',labels.sum())\n",
    "    print(preds)\n",
    "    preds = prob_to_label(preds,threshold=threshold)\n",
    "#     print('pred_sum: ',preds.sum())\n",
    "#     print(round(floss_macro(target = labels, prediction = preds),5))\n",
    "    return 'floss_macro', round(floss_macro(target = labels, prediction = preds),5)\n",
    "\n",
    "# def evalmcc(preds, dtrain):\n",
    "#     labels = dtrain.get_label()\n",
    "#     return 'MCC', matthews_corrcoef(labels, preds > THRESHOLD)\n",
    "\n",
    "\n",
    "def feval_floss_macro_2(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    preds = prob_to_label(preds,threshold=threshold)\n",
    "    return 'floss_macro_sk', round(floss_macro_2(target = labels, prediction = preds),5), False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric':'None', # (lambda y_true, y_pred: f1_score_custom(y_true, y_pred)),\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': 2 ** 7,\n",
    "            'early_stopping_rounds':200,\n",
    "            'lambda_l2': 10,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 4,\n",
    "            'learning_rate': 0.01,\n",
    "            'seed': 2021,\n",
    "            'n_jobs':-1,\n",
    "            'verbose': -1,\n",
    "        }\n",
    "\n",
    "lgbm_params = {\n",
    "            # Key Parameters\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt', # 'dart'\n",
    "            'learning_rate': 0.01,\n",
    "#             'num_iterations':100  # default=100\n",
    "            'early_stopping_rounds':200,    \n",
    "#             'min_child_weight': 5, #叶子上的最小样本数\n",
    "#             'max_depth': default=-1\n",
    "#             'num_leaves': 2 ** 7,  # default = 31(2**5-1)\n",
    "            'num_threads': -1, # 'n_jobs'\n",
    "                \n",
    "            # Learning Control Parameters\n",
    "#             'lambda_l1':\n",
    "            'lambda_l2': 10,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 4,\n",
    "    \n",
    "            'verbose': -1,\n",
    "            'seed': 2021,\n",
    "        }\n",
    "\n",
    "xgb_params={'booster': 'gbtree',\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric':'auc',\n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth':7, \n",
    "            'gamma':1,\n",
    "            'lambda': 10,\n",
    "            'eta':0.04, # default=0.3\n",
    "            'colsample_bytree':0.8, # 生成树时进行的列采样\n",
    "            'subsample':0.8, # 随机采样训练样本 \n",
    "#             'binary':'logistic',\n",
    "            'tree_method':'exact',#\n",
    "            'nthread':-1,\n",
    "            'seed':2021\n",
    "}\n",
    "\n",
    "cat_params = {'learning_rate': 0.05,\n",
    "              'depth': 7,\n",
    "              'l2_leaf_reg': 10,\n",
    "              'bootstrap_type': 'Bernoulli',\n",
    "              'od_type': 'Iter',\n",
    "              'eval_metric': feval_floss_macro,\n",
    "              'od_wait': 50,\n",
    "              'random_seed': 2021,\n",
    "              'allow_writing_files': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.DataFrame()                 # out-of-fold result\n",
    "cv_scores = []\n",
    "cv_scores_2 = []\n",
    "cv_scores_xgb = []\n",
    "cv_scores_xgb_2 = []\n",
    "cv_scores_cat = []\n",
    "cv_scores_cat_2 = []\n",
    "f1_list = []\n",
    "# cv_mean =[]\n",
    "# cv_std = []\n",
    "models = []                          # models\n",
    "scores = 0.0                         # validation score\n",
    "threshold = 0.25\n",
    "\n",
    "# thresholds = [0.238,0.239,0.240,0.241,0.242,0.243,0.244,0.245,\n",
    "#               0.246,0.247,0.248, 0.249,0.250,0.251,0.252,0.253]\n",
    "\n",
    "def cv_model(clf, X, y, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2021\n",
    "    kf = KFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        print(\"Fold :\", fold+1)\n",
    "        # create dataset\n",
    "        X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "        X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "        \n",
    "        if clf_name == 'lgb':\n",
    "            lgbm_train = lgbm.Dataset(X_train,y_train)\n",
    "            lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train)\n",
    "\n",
    "            # model \n",
    "            model = lgbm.train(params=base_params,\n",
    "                               train_set=lgbm_train,\n",
    "                               valid_sets=[lgbm_train, lgbm_valid],\n",
    "                               num_boost_round=5000,\n",
    "                               feval = feval_floss_macro,\n",
    "                               verbose_eval=200,\n",
    "        #                       categorical_feature = ['Driving_flag']        \n",
    "                             )\n",
    "            # validation \n",
    "            y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "            y_pred = prob_to_label(y_pred,threshold)\n",
    "\n",
    "#             FLOSS = round(floss(target= y_valid, prediction = y_pred),3)\n",
    "#             print(f'Performance of the　prediction: , floss: {FLOSS}')\n",
    "\n",
    "        #     cv_scores.append(roc_auc_score(y_valid, y_pred))\n",
    "            cv_scores.append(f1_score(y_valid, y_pred,average='macro'))\n",
    "            cv_scores_2.append(f1_score(y_valid, y_pred,average='micro'))\n",
    "\n",
    "            models.append(model)\n",
    "            print(\"*\" * 100)\n",
    "            \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(X_train, y_train)\n",
    "            valid_matrix = clf.DMatrix(X_valid, y_valid)\n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "\n",
    "            model = clf.train(xgb_params,\n",
    "                              train_matrix,\n",
    "                              num_boost_round=50000,\n",
    "                              evals=watchlist,\n",
    "#                               feval=feval_floss_macro_xgb,\n",
    "                              verbose_eval=200,\n",
    "                              early_stopping_rounds=200)\n",
    "            \n",
    "            y_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = prob_to_label(y_pred,threshold)\n",
    "            cv_scores.append(f1_score(y_valid, y_pred,average='macro'))\n",
    "            cv_scores_2.append(f1_score(y_valid, y_pred,average='micro'))\n",
    "#             pred_labels = prob_to_label(y_pred,i)\n",
    "#             f1 = f1_score(y_valid,pred_labels,average='macro')\n",
    "#             f1_list.append(f1)\n",
    "            models.append(model)\n",
    "            print(\"*\" * 100)\n",
    "#             test_pred = model.predict(test_x , ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        if clf_name == \"cat\":\n",
    "            model = clf(iterations=20000, **cat_params)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=(X_valid, y_valid),\n",
    "#                       cat_features=[],\n",
    "                      use_best_model=True,\n",
    "#                       eval_metric = feval_floss_macro,\n",
    "                      verbose=500)\n",
    "            \n",
    "            y_pred  = model.predict(X_valid)\n",
    "            y_pred = prob_to_label(y_pred,threshold)\n",
    "            cv_scores_cat.append(f1_score(y_valid, y_pred,average='macro'))\n",
    "            cv_scores_cat_2.append(f1_score(y_valid, y_pred,average='micro'))\n",
    "            models.append(model)\n",
    "            print(\"*\" * 100)\n",
    "#             test_pred = model.predict(test_x)\n",
    "\n",
    "    print('cv_score: ',cv_scores)    \n",
    "    print('avg_cv_score: ', np.average(np.array(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train):\n",
    "    lgb_train = cv_model(lgbm, x_train, y_train, \"lgb\")\n",
    "    return lgb_train\n",
    "\n",
    "def xgb_model(x_train, y_train):\n",
    "    xgb_train = cv_model(xgb, x_train, y_train, \"xgb\")\n",
    "    return xgb_train\n",
    "\n",
    "def cat_model(x_train, y_train):\n",
    "    cat_train = cv_model(CatBoostRegressor, x_train, y_train,\"cat\")\n",
    "    return cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's floss_macro: -0.6079\tvalid_1's floss_macro: -0.56553\n",
      "[400]\ttraining's floss_macro: -0.64445\tvalid_1's floss_macro: -0.58196\n",
      "[600]\ttraining's floss_macro: -0.66444\tvalid_1's floss_macro: -0.58435\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4fa17fa5220c>\u001b[0m in \u001b[0;36mlgb_model\u001b[1;34m(x_train, y_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mlgb_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lgb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlgb_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-c48b92bd2b4e>\u001b[0m in \u001b[0;36mcv_model\u001b[1;34m(clf, X, y, clf_name)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m# model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             model = lgbm.train(params=base_params,\n\u001b[0m\u001b[0;32m     35\u001b[0m                                \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgbm_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                                \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlgbm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgbm_valid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2641\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_train = lgb_model(X, y)\n",
    "# xgb_train = xgb_model(X, y)\n",
    "# cat_train = cat_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "[0]\ttrain-auc:0.62047\teval-auc:0.61523\n",
      "[200]\ttrain-auc:0.68244\teval-auc:0.64822\n",
      "[400]\ttrain-auc:0.70492\teval-auc:0.65777\n",
      "[600]\ttrain-auc:0.72208\teval-auc:0.66287\n",
      "[800]\ttrain-auc:0.73465\teval-auc:0.66499\n",
      "[1000]\ttrain-auc:0.74625\teval-auc:0.66617\n",
      "[1200]\ttrain-auc:0.75627\teval-auc:0.66673\n",
      "[1400]\ttrain-auc:0.76598\teval-auc:0.66679\n",
      "[1427]\ttrain-auc:0.76712\teval-auc:0.66674\n",
      "****************************************************************************************************\n",
      "Fold : 2\n",
      "[0]\ttrain-auc:0.62023\teval-auc:0.61263\n",
      "[200]\ttrain-auc:0.68173\teval-auc:0.64746\n",
      "[400]\ttrain-auc:0.70371\teval-auc:0.65682\n",
      "[600]\ttrain-auc:0.72122\teval-auc:0.66167\n",
      "[800]\ttrain-auc:0.73363\teval-auc:0.66407\n",
      "[1000]\ttrain-auc:0.74496\teval-auc:0.66555\n",
      "[1200]\ttrain-auc:0.75567\teval-auc:0.66649\n",
      "[1400]\ttrain-auc:0.76525\teval-auc:0.66685\n",
      "[1600]\ttrain-auc:0.77387\teval-auc:0.66712\n",
      "[1800]\ttrain-auc:0.78231\teval-auc:0.66721\n",
      "[2000]\ttrain-auc:0.78988\teval-auc:0.66731\n",
      "[2200]\ttrain-auc:0.79713\teval-auc:0.66733\n",
      "[2381]\ttrain-auc:0.80371\teval-auc:0.66729\n",
      "****************************************************************************************************\n",
      "Fold : 3\n",
      "[0]\ttrain-auc:0.61710\teval-auc:0.60764\n",
      "[200]\ttrain-auc:0.68156\teval-auc:0.64841\n",
      "[400]\ttrain-auc:0.70382\teval-auc:0.65738\n",
      "[600]\ttrain-auc:0.72117\teval-auc:0.66220\n",
      "[800]\ttrain-auc:0.73459\teval-auc:0.66417\n",
      "[1000]\ttrain-auc:0.74605\teval-auc:0.66521\n",
      "[1200]\ttrain-auc:0.75610\teval-auc:0.66583\n",
      "[1400]\ttrain-auc:0.76577\teval-auc:0.66609\n",
      "[1528]\ttrain-auc:0.77144\teval-auc:0.66608\n",
      "****************************************************************************************************\n",
      "Fold : 4\n",
      "[0]\ttrain-auc:0.62521\teval-auc:0.59846\n",
      "[200]\ttrain-auc:0.68396\teval-auc:0.63299\n",
      "[400]\ttrain-auc:0.70591\teval-auc:0.64237\n",
      "[600]\ttrain-auc:0.72395\teval-auc:0.64789\n",
      "[800]\ttrain-auc:0.73634\teval-auc:0.65047\n",
      "[1000]\ttrain-auc:0.74707\teval-auc:0.65204\n",
      "[1200]\ttrain-auc:0.75745\teval-auc:0.65270\n",
      "[1400]\ttrain-auc:0.76696\teval-auc:0.65307\n",
      "[1600]\ttrain-auc:0.77578\teval-auc:0.65318\n",
      "[1800]\ttrain-auc:0.78389\teval-auc:0.65298\n",
      "[1847]\ttrain-auc:0.78544\teval-auc:0.65289\n",
      "****************************************************************************************************\n",
      "Fold : 5\n",
      "[0]\ttrain-auc:0.62155\teval-auc:0.61310\n",
      "[200]\ttrain-auc:0.68271\teval-auc:0.64810\n",
      "[400]\ttrain-auc:0.70593\teval-auc:0.65653\n",
      "[600]\ttrain-auc:0.72333\teval-auc:0.66055\n",
      "[800]\ttrain-auc:0.73613\teval-auc:0.66211\n",
      "[1000]\ttrain-auc:0.74694\teval-auc:0.66265\n",
      "[1200]\ttrain-auc:0.75707\teval-auc:0.66306\n",
      "[1400]\ttrain-auc:0.76677\teval-auc:0.66312\n",
      "[1469]\ttrain-auc:0.76987\teval-auc:0.66298\n",
      "****************************************************************************************************\n",
      "cv_score:  [0.5857362652133077, 0.5891815176819459, 0.5845895375853442, 0.5772990665427377, 0.5846133215688808, 0.584228313690297, 0.5880506812568241, 0.5854364376679272, 0.5745832504602248, 0.5804018561203933]\n",
      "avg_cv_score:  0.5834120247787882\n",
      "Wall time: 25min 37s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# xgb_train = xgb_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.2.2 is available.\n",
      "You should consider upgrading via the 'd:\\program\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.9.0 in d:\\program\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14.0 in d:\\program\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in d:\\program\\anaconda\\lib\\site-packages (from bayesian-optimization) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\program\\anaconda\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\program\\anaconda\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.17.0)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py): started\n",
      "  Building wheel for bayesian-optimization (setup.py): finished with status 'done'\n",
      "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11690 sha256=b83b2e8ae3f5223a4aa79f1a5d8d6fe0d8d4210de93ddb42b5ca9808c2d59445\n",
      "  Stored in directory: c:\\users\\dingjun\\appdata\\local\\pip\\cache\\wheels\\37\\fa\\19\\f93e793d3944567a60b3ab93b446cf7370cc82c60c1d1c613f\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# 贝叶斯调参\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valia = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\"\"\"定义优化函数\"\"\"\n",
    "def rf_cv_lgb(num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf, \n",
    "              min_child_weight, min_split_gain, reg_lambda, reg_alpha):\n",
    "    # 建立模型\n",
    "    model_lgb = lgbm.LGBMClassifier(boosting_type='gbdt', \n",
    "                                   objective='binary', \n",
    "                                   metric='auc',\n",
    "                                   learning_rate=0.1, \n",
    "                                   n_estimators=5000,\n",
    "                                   num_leaves=int(num_leaves), \n",
    "                                   max_depth=int(max_depth), \n",
    "                                   bagging_fraction=round(bagging_fraction, 2), \n",
    "                                   feature_fraction=round(feature_fraction, 2),\n",
    "                                   bagging_freq=int(bagging_freq), \n",
    "                                   min_data_in_leaf=int(min_data_in_leaf),\n",
    "                                   min_child_weight=min_child_weight, \n",
    "                                   min_split_gain=min_split_gain,\n",
    "                                   reg_lambda=reg_lambda, \n",
    "                                   reg_alpha=reg_alpha,\n",
    "                                   n_jobs= -1\n",
    "                                  )\n",
    "    \n",
    "    cv_score = cross_val_score(model_lgb, X_train, y_train, cv=5, scoring='f1_macro').mean()\n",
    "    \n",
    "    return cv_score\n",
    "\n",
    "\n",
    "def rf_cv_xgb(num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf, \n",
    "              min_child_weight, min_split_gain, reg_lambda, reg_alpha):\n",
    "    # 建立模型\n",
    "    model_lgb = lgbm.LGBMClassifier(boosting_type='gbdt', \n",
    "                                   objective='binary', \n",
    "                                   metric='auc',\n",
    "                                   learning_rate=0.1, \n",
    "                                   n_estimators=5000,\n",
    "                                   num_leaves=int(num_leaves), \n",
    "                                   max_depth=int(max_depth), \n",
    "                                   bagging_fraction=round(bagging_fraction, 2), \n",
    "                                   feature_fraction=round(feature_fraction, 2),\n",
    "                                   bagging_freq=int(bagging_freq), \n",
    "                                   min_data_in_leaf=int(min_data_in_leaf),\n",
    "                                   min_child_weight=min_child_weight, \n",
    "                                   min_split_gain=min_split_gain,\n",
    "                                   reg_lambda=reg_lambda, \n",
    "                                   reg_alpha=reg_alpha,\n",
    "                                   n_jobs= -1\n",
    "                                  )\n",
    "    \n",
    "    cv_score = cross_val_score(model_lgb, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | baggin... | featur... | max_depth | min_ch... | min_da... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.92, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6585  \u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 43.98   \u001b[0m | \u001b[0m 0.9248  \u001b[0m | \u001b[0m 8.582   \u001b[0m | \u001b[0m 4.004   \u001b[0m | \u001b[0m 98.96   \u001b[0m | \u001b[0m 0.9086  \u001b[0m | \u001b[0m 41.58   \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 3.533   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6539  \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 98.29   \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 5.917   \u001b[0m | \u001b[0m 1.343   \u001b[0m | \u001b[0m 82.23   \u001b[0m | \u001b[0m 0.1708  \u001b[0m | \u001b[0m 92.97   \u001b[0m | \u001b[0m 2.774   \u001b[0m | \u001b[0m 5.672   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.67, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.67\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.57, subsample=1.0 will be ignored. Current value: bagging_fraction=0.57\n",
      "[LightGBM] [Warning] bagging_freq is set=40, subsample_freq=0 will be ignored. Current value: bagging_freq=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.67, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.67\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.57, subsample=1.0 will be ignored. Current value: bagging_fraction=0.57\n",
      "[LightGBM] [Warning] bagging_freq is set=40, subsample_freq=0 will be ignored. Current value: bagging_freq=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.67, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.67\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.57, subsample=1.0 will be ignored. Current value: bagging_fraction=0.57\n",
      "[LightGBM] [Warning] bagging_freq is set=40, subsample_freq=0 will be ignored. Current value: bagging_freq=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.67, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.67\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.57, subsample=1.0 will be ignored. Current value: bagging_fraction=0.57\n",
      "[LightGBM] [Warning] bagging_freq is set=40, subsample_freq=0 will be ignored. Current value: bagging_freq=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.67, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.67\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.57, subsample=1.0 will be ignored. Current value: bagging_fraction=0.57\n",
      "[LightGBM] [Warning] bagging_freq is set=40, subsample_freq=0 will be ignored. Current value: bagging_freq=40\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6353  \u001b[0m | \u001b[0m 0.5712  \u001b[0m | \u001b[0m 40.36   \u001b[0m | \u001b[0m 0.6708  \u001b[0m | \u001b[0m 8.956   \u001b[0m | \u001b[0m 5.545   \u001b[0m | \u001b[0m 44.39   \u001b[0m | \u001b[0m 0.2524  \u001b[0m | \u001b[0m 150.6   \u001b[0m | \u001b[0m 2.358   \u001b[0m | \u001b[0m 5.243   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.62, subsample=1.0 will be ignored. Current value: bagging_fraction=0.62\n",
      "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.62, subsample=1.0 will be ignored. Current value: bagging_fraction=0.62\n",
      "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.62, subsample=1.0 will be ignored. Current value: bagging_fraction=0.62\n",
      "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.62, subsample=1.0 will be ignored. Current value: bagging_fraction=0.62\n",
      "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.62, subsample=1.0 will be ignored. Current value: bagging_fraction=0.62\n",
      "[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6086  \u001b[0m | \u001b[0m 0.6227  \u001b[0m | \u001b[0m 38.75   \u001b[0m | \u001b[0m 0.8298  \u001b[0m | \u001b[0m 10.81   \u001b[0m | \u001b[0m 1.794   \u001b[0m | \u001b[0m 89.24   \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 70.01   \u001b[0m | \u001b[0m 0.02432 \u001b[0m | \u001b[0m 2.525   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] bagging_freq is set=57, subsample_freq=0 will be ignored. Current value: bagging_freq=57\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] bagging_freq is set=57, subsample_freq=0 will be ignored. Current value: bagging_freq=57\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] bagging_freq is set=57, subsample_freq=0 will be ignored. Current value: bagging_freq=57\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] bagging_freq is set=57, subsample_freq=0 will be ignored. Current value: bagging_freq=57\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=77, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=77\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] bagging_freq is set=57, subsample_freq=0 will be ignored. Current value: bagging_freq=57\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6072  \u001b[0m | \u001b[0m 0.7888  \u001b[0m | \u001b[0m 57.86   \u001b[0m | \u001b[0m 0.5949  \u001b[0m | \u001b[0m 14.43   \u001b[0m | \u001b[0m 9.373   \u001b[0m | \u001b[0m 77.08   \u001b[0m | \u001b[0m 0.009322\u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 0.001958\u001b[0m | \u001b[0m 9.184   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.52, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] bagging_freq is set=47, subsample_freq=0 will be ignored. Current value: bagging_freq=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.52, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] bagging_freq is set=47, subsample_freq=0 will be ignored. Current value: bagging_freq=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.52, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] bagging_freq is set=47, subsample_freq=0 will be ignored. Current value: bagging_freq=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.52, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] bagging_freq is set=47, subsample_freq=0 will be ignored. Current value: bagging_freq=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.52, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] bagging_freq is set=47, subsample_freq=0 will be ignored. Current value: bagging_freq=47\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.6589  \u001b[0m | \u001b[95m 0.7712  \u001b[0m | \u001b[95m 47.39   \u001b[0m | \u001b[95m 0.5234  \u001b[0m | \u001b[95m 11.24   \u001b[0m | \u001b[95m 4.729   \u001b[0m | \u001b[95m 97.01   \u001b[0m | \u001b[95m 0.5749  \u001b[0m | \u001b[95m 44.83   \u001b[0m | \u001b[95m 6.355   \u001b[0m | \u001b[95m 6.019   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] bagging_freq is set=58, subsample_freq=0 will be ignored. Current value: bagging_freq=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] bagging_freq is set=58, subsample_freq=0 will be ignored. Current value: bagging_freq=58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] bagging_freq is set=58, subsample_freq=0 will be ignored. Current value: bagging_freq=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] bagging_freq is set=58, subsample_freq=0 will be ignored. Current value: bagging_freq=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] bagging_freq is set=58, subsample_freq=0 will be ignored. Current value: bagging_freq=58\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 0.862   \u001b[0m | \u001b[0m 58.22   \u001b[0m | \u001b[0m 0.9542  \u001b[0m | \u001b[0m 13.93   \u001b[0m | \u001b[0m 1.716   \u001b[0m | \u001b[0m 99.2    \u001b[0m | \u001b[0m 0.4528  \u001b[0m | \u001b[0m 27.4    \u001b[0m | \u001b[0m 0.1472  \u001b[0m | \u001b[0m 9.06    \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 37.6    \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 15.58   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 85.52   \u001b[0m | \u001b[0m 0.2262  \u001b[0m | \u001b[0m 25.73   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6558  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 78.22   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 44.09   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6553  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.9461  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 3.82    \u001b[0m | \u001b[0m 70.9    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 9.899   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.99, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 0.6617  \u001b[0m | \u001b[0m 44.42   \u001b[0m | \u001b[0m 0.9904  \u001b[0m | \u001b[0m 6.827   \u001b[0m | \u001b[0m 4.787   \u001b[0m | \u001b[0m 97.17   \u001b[0m | \u001b[0m 0.2406  \u001b[0m | \u001b[0m 43.04   \u001b[0m | \u001b[0m 6.932   \u001b[0m | \u001b[0m 2.929   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6242  \u001b[0m | \u001b[0m 0.8857  \u001b[0m | \u001b[0m 93.51   \u001b[0m | \u001b[0m 0.7494  \u001b[0m | \u001b[0m 19.24   \u001b[0m | \u001b[0m 9.939   \u001b[0m | \u001b[0m 93.46   \u001b[0m | \u001b[0m 0.04107 \u001b[0m | \u001b[0m 58.34   \u001b[0m | \u001b[0m 1.387   \u001b[0m | \u001b[0m 5.784   \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=34, subsample_freq=0 will be ignored. Current value: bagging_freq=34\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.6594  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 34.67   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 20.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 32.78   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 10.0    \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.97, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.97, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.97, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.97, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.97, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6551  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.9744  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 53.65   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 79.05   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 9.64    \u001b[0m |\n",
      "[LightGBM] [Warning] feature_fraction is set=0.96, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.96\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.96, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.96\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.96, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.96\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.96, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.96\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.96, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.96\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6551  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 42.54   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 49.22   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 4.24    \u001b[0m |\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\"\"\"定义优化参数\"\"\"\n",
    "bayes_lgb = BayesianOptimization(\n",
    "    rf_cv_lgb, \n",
    "    {\n",
    "        'num_leaves':(10, 200),\n",
    "        'max_depth':(3, 20),\n",
    "        'bagging_fraction':(0.5, 1.0),\n",
    "        'feature_fraction':(0.5, 1.0),\n",
    "        'bagging_freq':(0, 100),\n",
    "        'min_data_in_leaf':(10,100),\n",
    "        'min_child_weight':(0, 10),\n",
    "        'min_split_gain':(0.0, 1.0),\n",
    "        'reg_alpha':(0.0, 10),\n",
    "        'reg_lambda':(0.0, 10),\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"开始优化\"\"\"\n",
    "bayes_lgb.maximize(n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold--0\n",
      "[LightGBM] [Info] Number of positive: 21164, number of negative: 98836\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6658\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176367 -> initscore=-1.541160\n",
      "[LightGBM] [Info] Start training from score -1.541160\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttraining's auc: 0.659622\tvalid_1's auc: 0.644329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.677968\tvalid_1's auc: 0.654109\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f40b840494ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# 最后进行调参\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m LGB_CV(\n\u001b[0m\u001b[0;32m     52\u001b[0m           \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m           \u001b[0mnum_leaves\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-f40b840494ba>\u001b[0m in \u001b[0;36mLGB_CV\u001b[1;34m(max_depth, num_leaves, min_data_in_leaf, feature_fraction, bagging_fraction, lambda_l1)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 }\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# 因为是交叉验证的算法，这里直接使用train，valid_sets就是要评估的数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         model = lgbm.train(params, \n\u001b[0m\u001b[0;32m     37\u001b[0m                           \u001b[0mlgbm_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                           \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlgbm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgbm_valid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2854\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2855\u001b[0m         \"\"\"\n\u001b[1;32m-> 2856\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   3380\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3381\u001b[0m             \u001b[0mtmp_out_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3382\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterGetEval(\n\u001b[0m\u001b[0;32m   3383\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def LGB_CV(\n",
    "          max_depth,\n",
    "          num_leaves,\n",
    "          min_data_in_leaf,\n",
    "          feature_fraction,\n",
    "          bagging_fraction,\n",
    "          lambda_l1\n",
    "         ):\n",
    "    # 这里就不采用交叉验证的cv_score = cross_val_score(model, x, y, scoring=\"f1\", cv=5)\n",
    "    folds = 5\n",
    "    seed = 2021\n",
    "    kf = KFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "    # f是准备存储预测值的，交叉验证下，用五份数据作为验证集，最后将这五份数据放回f里\n",
    "    f = np.zeros(X.shape[0])\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X,y)):\n",
    "        print(\"fold--{}\".format(fold))\n",
    "        \n",
    "        X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "        X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "        lgbm_train = lgbm.Dataset(X_train,y_train)\n",
    "        lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train)\n",
    "        \n",
    "\n",
    "        params = {'num_leaves': int(num_leaves),\n",
    "                'min_data_in_leaf': int(min_data_in_leaf), \n",
    "                'objective':'binary',\n",
    "                'max_depth': int(max_depth),\n",
    "                'learning_rate': 0.01,\n",
    "                \"boosting\": \"gbdt\",\n",
    "                \"feature_fraction\": feature_fraction,\n",
    "                \"bagging_fraction\": bagging_fraction ,\n",
    "                \"metric\": 'auc',\n",
    "                \"lambda_l1\": lambda_l1,\n",
    "                }\n",
    "        # 因为是交叉验证的算法，这里直接使用train，valid_sets就是要评估的数据集\n",
    "        model = lgbm.train(params, \n",
    "                          lgbm_train, \n",
    "                          valid_sets=[lgbm_train, lgbm_valid],\n",
    "                          num_boost_round=5000, \n",
    "                          verbose_eval=200,\n",
    "                          early_stopping_rounds = 200)\n",
    "        # 返回迭代中最好的数据,这里的predict里面的数据（不需要经过dataset）不需要再进行转化，如果是xgboost就需要，需要把x_test进行转化DMatrix(x_test),这里x_test不包含类别特征\n",
    "        f[val_index] = model.predict(X[val_index], num_iteration=model.best_iteration)\n",
    "        # predict里面的验证集不需要进行dataset，但是xgboost算法时需要dmatrix，并且只需要DMatrix(x_test),这里x_test不包含类别特征,很多地方这里都会出错，直接带着类别就去预测\n",
    "        del model, trn_idx, val_idx\n",
    "    # 由于输出的是概率值，转化为0，1的整型值 \n",
    "    f = np.array([1 if i>0.25 else 0 for i in f])\n",
    "    return metrics.f1_score(f, y)\n",
    "    \n",
    "# 最后进行调参\n",
    "LGB_CV(\n",
    "          max_depth=5,\n",
    "          num_leaves=32,\n",
    "          min_data_in_leaf=1,\n",
    "          feature_fraction=0.8,\n",
    "          bagging_fraction=0.8,\n",
    "          lambda_l1=None\n",
    "         )\n",
    "\n",
    "# 采用贝叶斯优化算法\n",
    "lgb_ba = BayesianOptimization(LGB_CV, \n",
    "        {\n",
    "        'num_leaves':(10, 200),\n",
    "        'max_depth':(3, 20),\n",
    "        'bagging_fraction':(0.5, 1.0),\n",
    "        'feature_fraction':(0.5, 1.0),\n",
    "        'bagging_freq':(0, 100),\n",
    "        'min_data_in_leaf':(10,100),\n",
    "        'min_child_weight':(0, 10),\n",
    "        'min_split_gain':(0.0, 1.0),\n",
    "        'reg_alpha':(0.0, 10),\n",
    "        'reg_lambda':(0.0, 10)\n",
    "        })\n",
    "lgb_ba.maximize()\n",
    "lgb_ba.max[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            lgbm_train = lgbm.Dataset(X_train,y_train)\n",
    "            lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train)\n",
    "\n",
    "            # model \n",
    "            model = lgbm.train(params=base_params,\n",
    "                               train_set=lgbm_train,\n",
    "                               valid_sets=[lgbm_train, lgbm_valid],\n",
    "                               num_boost_round=5000,\n",
    "                               feval = feval_floss_macro,\n",
    "                               verbose_eval=200,\n",
    "        #                       categorical_feature = ['Driving_flag']        \n",
    "                             )\n",
    "            # validation\n",
    "            y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "            y_pred = prob_to_label(y_pred,threshold)\n",
    "\n",
    "#             FLOSS = round(floss(target= y_valid, prediction = y_pred),3)\n",
    "#             print(f'Performance of the　prediction: , floss: {FLOSS}')\n",
    "\n",
    "        #     cv_scores.append(roc_auc_score(y_valid, y_pred))\n",
    "            cv_scores.append(f1_score(y_valid, y_pred,average='macro'))\n",
    "            cv_scores_2.append(f1_score(y_valid, y_pred,average='micro'))\n",
    "\n",
    "            models.append(model)\n",
    "            print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature=['branch_id','supplier_id','manufacturer_id','area_id','employee_code_id',\\\n",
    "                    'mobileno_flag','idcard_flag','Driving_flag','passport_flag',\\\n",
    "                    'Credit_level','employment_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.710605\tvalid_1's auc: 0.657079\n",
      "[400]\ttraining's auc: 0.743375\tvalid_1's auc: 0.664056\n",
      "[600]\ttraining's auc: 0.769489\tvalid_1's auc: 0.666376\n",
      "[800]\ttraining's auc: 0.790968\tvalid_1's auc: 0.666099\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's auc: 0.772002\tvalid_1's auc: 0.666507\n",
      "****************************************************************************************************\n",
      "Fold : 2\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.710689\tvalid_1's auc: 0.656881\n",
      "[400]\ttraining's auc: 0.742973\tvalid_1's auc: 0.662915\n",
      "[600]\ttraining's auc: 0.768295\tvalid_1's auc: 0.66488\n",
      "[800]\ttraining's auc: 0.789766\tvalid_1's auc: 0.665391\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's auc: 0.787422\tvalid_1's auc: 0.665463\n",
      "****************************************************************************************************\n",
      "Fold : 3\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.71162\tvalid_1's auc: 0.657141\n",
      "[400]\ttraining's auc: 0.743596\tvalid_1's auc: 0.66323\n",
      "[600]\ttraining's auc: 0.769338\tvalid_1's auc: 0.664964\n",
      "[800]\ttraining's auc: 0.790535\tvalid_1's auc: 0.665227\n",
      "[1000]\ttraining's auc: 0.808913\tvalid_1's auc: 0.665032\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's auc: 0.798366\tvalid_1's auc: 0.66538\n",
      "****************************************************************************************************\n",
      "Fold : 4\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.713081\tvalid_1's auc: 0.641654\n",
      "[400]\ttraining's auc: 0.744844\tvalid_1's auc: 0.649248\n",
      "[600]\ttraining's auc: 0.770336\tvalid_1's auc: 0.651817\n",
      "[800]\ttraining's auc: 0.791528\tvalid_1's auc: 0.652412\n",
      "[1000]\ttraining's auc: 0.809703\tvalid_1's auc: 0.652432\n",
      "[1200]\ttraining's auc: 0.825579\tvalid_1's auc: 0.652099\n",
      "Early stopping, best iteration is:\n",
      "[1010]\ttraining's auc: 0.810576\tvalid_1's auc: 0.652542\n",
      "****************************************************************************************************\n",
      "Fold : 5\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.711368\tvalid_1's auc: 0.655394\n",
      "[400]\ttraining's auc: 0.743682\tvalid_1's auc: 0.661086\n",
      "[600]\ttraining's auc: 0.76887\tvalid_1's auc: 0.661956\n",
      "[800]\ttraining's auc: 0.790039\tvalid_1's auc: 0.661921\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's auc: 0.773457\tvalid_1's auc: 0.662211\n",
      "****************************************************************************************************\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, random_state=2021, shuffle=True)\n",
    "oof = pd.DataFrame()                 # out-of-fold result\n",
    "cv_scores = []\n",
    "models = []                          # models\n",
    "scores = 0.0                         # validation score\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    print(\"Fold :\", fold+1)\n",
    "    \n",
    "    # create dataset\n",
    "    X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "    X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "    \n",
    "    lgbm_train = lgbm.Dataset(X_train,y_train)\n",
    "    lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train)\n",
    "    \n",
    "    # model \n",
    "    model = lgbm.train(params=base_params,\n",
    "                      train_set=lgbm_train,\n",
    "                      valid_sets=[lgbm_train, lgbm_valid],\n",
    "                      num_boost_round=5000,         \n",
    "                      verbose_eval=200,\n",
    "#                       categorical_feature = ['Driving_flag']        \n",
    "                     )\n",
    "    \n",
    "    # validation \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    \n",
    "    cv_scores.append(roc_auc_score(y_valid, y_pred))\n",
    "#     cv_scores.append(f1_score(val_y, val_pred,average='macro'))\n",
    "\n",
    "\n",
    "#     RMSPE = round(rmspe(y_true = y_valid, y_pred = y_pred),3)\n",
    "#     print(f'Performance of the　prediction: , RMSPE: {RMSPE}')\n",
    "\n",
    "#     #keep scores and models\n",
    "#     scores += RMSPE / 5\n",
    "    models.append(model)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm_scotrainre_list: [0.6665074037191319, 0.665462735236708, 0.6653798253532002, 0.6525417062717462, 0.662211448505362]\n",
      "lgbm_score_mean: 0.6624206238172297\n",
      "lgbm_score_std: 0.005144897506601224\n"
     ]
    }
   ],
   "source": [
    "print(\"%s_scotrainre_list:\" % 'lgbm', cv_scores)\n",
    "print(\"%s_score_mean:\" % 'lgbm', np.mean(cv_scores))\n",
    "print(\"%s_score_std:\" % 'lgbm', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['customer_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_arr = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966bbad10f149928a96a04a07cb1d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in tqdm(models,total=len(models)):\n",
    "    pred = model.predict(X_test[X_valid.columns], num_iteration=model.best_iteration)\n",
    "    target_arr += pred / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.133412\n",
       "1        0.090725\n",
       "2        0.217693\n",
       "3        0.146264\n",
       "4        0.094359\n",
       "           ...   \n",
       "29995    0.253608\n",
       "29996    0.101897\n",
       "29997    0.079226\n",
       "29998    0.202307\n",
       "29999    0.160320\n",
       "Length: 30000, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.Series(target_arr)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  loan_default\n",
       "0        14342             0\n",
       "1        94753             0\n",
       "2       140283             0\n",
       "3       134742             0\n",
       "4         4749             0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         14342\n",
       "1         94753\n",
       "2        140283\n",
       "3        134742\n",
       "4          4749\n",
       "          ...  \n",
       "29995    100643\n",
       "29996    166843\n",
       "29997      4084\n",
       "29998    171136\n",
       "29999    113851\n",
       "Name: customer_id, Length: 30000, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_id_test = test.customer_id\n",
    "customer_id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_id_test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.133412\n",
       "1        0.090725\n",
       "2        0.217693\n",
       "3        0.146264\n",
       "4        0.094359\n",
       "           ...   \n",
       "29995    0.253608\n",
       "29996    0.101897\n",
       "29997    0.079226\n",
       "29998    0.202307\n",
       "29999    0.160320\n",
       "Length: 30000, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_features=[customer_id_test,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>100643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>166843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>4084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>171136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>113851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id  loan_default\n",
       "0            14342             0\n",
       "1            94753             0\n",
       "2           140283             0\n",
       "3           134742             0\n",
       "4             4749             0\n",
       "...            ...           ...\n",
       "29995       100643             1\n",
       "29996       166843             0\n",
       "29997         4084             0\n",
       "29998       171136             0\n",
       "29999       113851             0\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat(concat_features,axis=1)\n",
    "submission.rename(columns={0:'loan_default'},inplace = True)\n",
    "threshold=0.245\n",
    "submission['loan_default'] = submission['loan_default'].apply(lambda x:1 if x>threshold else 0).values\n",
    "# submission = pd.DataFrame(data=target,columns=['loan_submit'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.176967\n",
       "Name: loan_default, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['loan_default'].value_counts()\n",
    "num_of_1 = train.loc[train.loan_default==1,'loan_default'].value_counts()\n",
    "num_of_1/len(train['loan_default'])\n",
    "# train.loc[train['loan_default']==1, 'loan_default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24055\n",
       "1     5945\n",
       "Name: loan_default, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['loan_default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.198167\n",
       "Name: loan_default, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_1_test = submission.loc[submission.loan_default==1,'loan_default'].value_counts()\n",
    "num_of_1_test/len(submission['loan_default'])\n",
    "# submission['loan_default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_lgbm_728_3.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
